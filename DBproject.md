**DB Project (Система обработки и анализа логов)**

![](/scheme.JPG)

Здравствуйте!
В качестве своего проекта думаю реализовать вот такаю схему как на картинке.
Все что до ETL->PostgreSQL будет забирать, нормализовать сырые логи, затем, например в конце каждого дня, по каким-то критериям будет запускаться механизм ETL и наполнять некими итоговыми за день данными PostgreSQL с последующим хранением(например в течении года) в нем этой информации. Все что за день обработал Elastic будет удаляться в нем.

Получится что Elastic + его обвязка обрабатывает сырые логи, отдает обработанный результат на хранение в PostgreSQL, после того как отдал, Elastic все очищает у себя и так каждый день.
На данном этапе все без кластера.

**Каие таблицы и поля будут в PostgreSQL**
![](/tables.JPG)

**Наполнение таблиц будет похоже на это:**

![](/data_from_elasticsearch.JPG "data_from_elasticsearch") ![](/warning_type_description.JPG "warning_type_description")

![](/join2tables.JPG "join2tables")
